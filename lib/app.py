import sys
print(sys.version)

print("‚è≥ Starting app.py...")

# Try importing required libraries
try:
    import cv2
    print("‚úÖ cv2 imported successfully")
except Exception as e:
    print(f"‚ùå Error importing cv2: {e}")

try:
    import os
    print("‚úÖ os imported successfully")
except Exception as e:
    print(f"‚ùå Error importing os: {e}")

try:
    import tempfile
    print("‚úÖ tempfile imported successfully")
except Exception as e:
    print(f"‚ùå Error importing tempfile: {e}")

try:
    import tensorflow as tf
    print("‚úÖ tf imported successfully")
except Exception as e:
    print(f"‚ùå Error importing tf: {e}")

try:
    import mediapipe as mp
    print("‚úÖ mediapipe imported successfully")
except Exception as e:
    print(f"‚ùå Error importing mediapipe: {e}")

try:
    import numpy as np
    print("‚úÖ numpy imported successfully")
except Exception as e:
    print(f"‚ùå Error importing numpy: {e}")

try:
    from flask import Flask, request, jsonify
    print("‚úÖ flask imported successfully")
except Exception as e:
    print(f"‚ùå Error importing flask: {e}")

print("‚è≥ Starting app.py...")

# Load the Keras model
model_path = os.path.join(os.path.dirname(__file__), 'models', '100model.h5')
print(f"üîÑ Loading model from {model_path}...")
model = tf.keras.models.load_model(model_path)
model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])
print("‚úÖ Model loaded.")

# Define your classes and parameters
actions = [
    'baby','eat','father','finish','good','happy','hear','house','important',
    'love','mall','me','mosque','mother','normal','sad','stop','thanks',
    'thinking','worry'
]
threshold = 0.85
window_size = 30
motion_threshold = 0.3

# Initialize MediaPipe Holistic
mp_holistic = mp.solutions.holistic
print("‚úÖ MediaPipe Holistic ready.")

app = Flask(__name__)

def extract_keypoints(results):
    pose = (np.array([[res.x, res.y, res.z, res.visibility] 
              for res in results.pose_landmarks.landmark]).flatten()
            if results.pose_landmarks else np.zeros(33*4))
    face = (np.array([[res.x, res.y, res.z] 
              for res in results.face_landmarks.landmark]).flatten()
            if results.face_landmarks else np.zeros(468*3))
    lh = (np.array([[res.x, res.y, res.z] 
             for res in results.left_hand_landmarks.landmark]).flatten()
          if results.left_hand_landmarks else np.zeros(21*3))
    rh = (np.array([[res.x, res.y, res.z] 
             for res in results.right_hand_landmarks.landmark]).flatten()
          if results.right_hand_landmarks else np.zeros(21*3))
    return np.concatenate([pose, face, lh, rh])

def motion_filter(seq):
    if len(seq) < 2:
        return False
    diff = np.diff(seq[-2:], axis=0)
    hand_motion = np.linalg.norm(diff[:, :42], axis=1).mean()
    body_motion = np.linalg.norm(diff[:, 42:42+132], axis=1).mean()
    face_motion = np.linalg.norm(diff[:, 42+132:], axis=1).mean()
    weighted = 0.8*hand_motion + 0.15*body_motion + 0.05*face_motion
    print(f"üîç Motion filter: hand={hand_motion:.4f}, body={body_motion:.4f}, face={face_motion:.4f}, weighted={weighted:.4f}")
    return weighted > motion_threshold

@app.route('/translate_video', methods=['POST'])
def translate_video():
    print("üì• /translate_video called")
    file = request.files.get('video')
    if not file:
        print("‚ùå No video file received")
        return "No video provided", 400

    # Save to temp (Windows‚Äësafe)
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    tmp_path = tmp.name
    tmp.close()                    # <-- release Python lock on file
    file.save(tmp_path)
    print(f"üíæ Saved uploaded video to {tmp_path}")

    # Extract frames
    cap = cv2.VideoCapture(tmp_path)
    frames = []
    idx = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)
        idx += 1
    cap.release()                 # <-- release OpenCV lock
    print(f"üéûÔ∏è Extracted {len(frames)} frames")

    # Delete temp file now that it's closed
    try:
        os.unlink(tmp_path)
        print(f"üóëÔ∏è Deleted temp file {tmp_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not delete temp file: {e}")

    # Process frames in Mediapipe + model
    seq = []
    sentence = []
    with mp_holistic.Holistic(
        static_image_mode=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as holistic:
        for i, frame in enumerate(frames):
            print(f"üîÑ Frame {i+1}/{len(frames)} processing")
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = holistic.process(rgb)
            kp = extract_keypoints(results)

            seq.append(kp)
            if len(seq) > window_size:
                seq.pop(0)

            if len(seq) == window_size and motion_filter(seq):
                input_data = np.expand_dims(seq, axis=0)
                res_probs = model.predict(input_data)[0]
                print(f"ü§ñ Model probs: {res_probs}")

                if np.max(res_probs) > threshold:
                    action = actions[np.argmax(res_probs)]
                    if not sentence or action != sentence[-1]:
                        sentence.append(action)
                        print(f"‚úÖ Detected action: {action}")

                if len(sentence) > 5:
                    sentence = sentence[-5:]

    final_sentence = ' '.join(sentence) if sentence else '---'
    print(f"üèÅ Final sentence: {final_sentence}")
    return final_sentence, 200

if __name__ == '__main__':
    print("üöÄ Starting Flask server on port 5000")
    app.run(host='0.0.0.0', port=5000, debug=True)